{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/adding-model-reg/wandb-model-registry/Model_Registry_E2E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbrgzOL6yoHl"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<!--- @wandbcode{tables_mendeleev} -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IFTzbJ4yoHn"
      },
      "source": [
        "# Artifacts and Model Registry Walkthrough \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# source directory for all raw data\n",
        "DATA_SRC = \"nature_100\"\n",
        "IMAGES_PER_LABEL = 10\n",
        "BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
        "SRC = DATA_SRC\n",
        "PREFIX = \"GCS\" # convenient for tracking local data\n",
        "PROJECT_NAME = \"Model Registry E2E\" #@param {type:\"string\"}\n",
        "ENTITY=\"kenlee\"#@param {type:\"string\"}\n",
        "dataset_name = \"mnist\"\n",
        "\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = IMAGES_PER_LABEL * 10\n",
        "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(TOTAL_IMAGES)])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9ClBV4ed4Gqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVluenCvyoHr"
      },
      "source": [
        "# Model Registry Overview\n",
        "![dataset_card_overview](https://drive.google.com/uc?export=view&id=1YowpB4dDxdqlXhcRD1Wjfe2jONT9jBgt)\n",
        "\n",
        "1. Checkpoint the model every epoch and log as an artifact\n",
        "2. Link your best model to a **Model Collection** in the Model Registry\n",
        "3. Retrieve the model from the collection for downstream evaluation or inference\n",
        "4. Add aliases depending on stage of model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNGoy_vlyoHo"
      },
      "outputs": [],
      "source": [
        "# set SIZE to \"TINY\", \"SMALL\", \"MEDIUM\", or \"LARGE\"\n",
        "# to select one of these three datasets\n",
        "# TINY dataset: 100 images, 30MB\n",
        "# SMALL dataset: 1000 images, 312MB\n",
        "# MEDIUM dataset: 5000 images, 1.5GB\n",
        "# LARGE dataset: 12,000 images, 3.6GB\n",
        "\n",
        "SIZE = \"TINY\"\n",
        "\n",
        "if SIZE == \"TINY\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
        "  src_zip = \"nature_100.zip\"\n",
        "  DATA_SRC = \"nature_100\"\n",
        "  IMAGES_PER_LABEL = 10\n",
        "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
        "elif SIZE == \"SMALL\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
        "  src_zip = \"nature_1K.zip\"\n",
        "  DATA_SRC = \"nature_1K\"\n",
        "  IMAGES_PER_LABEL = 100\n",
        "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
        "elif SIZE == \"MEDIUM\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "  src_zip = \"nature_12K.zip\"\n",
        "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
        "  IMAGES_PER_LABEL = 500\n",
        "  BALANCED_SPLITS = {\"train\" : 400, \"val\" : 50, \"test\": 50}\n",
        "elif SIZE == \"LARGE\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "  src_zip = \"nature_12K.zip\"\n",
        "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
        "  IMAGES_PER_LABEL = 1000\n",
        "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVOiJTICyoHp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!unzip $src_zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hjue9_yyoHp"
      },
      "source": [
        "# Step 0: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqooDzRSyoHp"
      },
      "source": [
        "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
        "\n",
        "\n",
        "*   `pip install wandb` – Install the W&B library\n",
        "*   `import wandb` – Import the wandb library\n",
        "*   `wandb login` – Login to your W&B account so you can log all your metrics in one place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaBhTchfyoHq"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Create a Model Collection!\n",
        "![](https://drive.google.com/uc?id=1z4LIigng9FV9C-nnCEATJFhVQpt3m7TJ)\n",
        "\n",
        "## Put the collection under the `model-registry` project in the team you want to make your model visible to:\n",
        "\n",
        "![](https://drive.google.com/uc?id=1YmsJrN9pAr1rPFJDYezaDfy8RCVHXUXG)\n",
        "\n"
      ],
      "metadata": {
        "id": "bQDravN-GenA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07R3zCGgyoHq"
      },
      "source": [
        "# Step 2: Log training data as an artifact\n",
        "0. Initialize Run with `wandb.init()`\n",
        "1. Create an artifact with `wandb.Artifact`\n",
        "2. Add cloud directories, files to the artifact with `artifact.add`\n",
        "3. Log the artifact with `wandb.log_artifact`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l nature_100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQZDCnSUhLmV",
        "outputId": "38506f2c-fd86-4a45-ffbe-d1bd15affd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 40\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Amphibia\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Animalia\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Arachnida\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Aves\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Fungi\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Insecta\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Mammalia\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Mollusca\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Plantae\n",
            "drwxr-xr-x 2 root root 4096 Dec 18  2020 Reptilia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"upload_data\")\n",
        "\n",
        "raw_data_art = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
        "raw_data_art.add_dir(DATA_SRC)\n",
        "run.log_artifact(raw_data_art)\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "72ad1637f6c944e8a0ecca85ba0b5730",
            "8425455933154828bbf653a29dc5400c",
            "437d1d7dea214f88b05e84fcea131c01",
            "0b470a79941c496d96e568e738e18e36",
            "717fac51259b4dce9197ade57b2add7c",
            "b5a69e61ef5848af80d7ff054fec742c",
            "a0822b4596474cd98aa2bbffd126c86c",
            "fea4979a0d03432bac5c9c07750e2d7f"
          ]
        },
        "id": "k1fPBxkF5Z3g",
        "outputId": "b85b6e9e-8c7d-41be-a9e2-9d3b9adf08e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220727_163611-1wbcpuq2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/1wbcpuq2\" target=\"_blank\">colorful-cherry-6</a></strong> to <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./nature_100)... Done. 0.3s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.729 MB of 0.729 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72ad1637f6c944e8a0ecca85ba0b5730"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">colorful-cherry-6</strong>: <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/1wbcpuq2\" target=\"_blank\">https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/1wbcpuq2</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220727_163611-1wbcpuq2/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trvPpGlMyoHr"
      },
      "source": [
        "# Log preprocessed/split data as artifact\n",
        "- For example, a preprocessing job produces a tokenized or augmented dataset that is then utilized by a training job\n",
        "- Each job is a run logged in W&B\n",
        "- Declare dependency of a run on an artifact with `wandb.use_artifact`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dnf9VpnyoHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157,
          "referenced_widgets": [
            "636dea55aa7b4a17b7d01e2d72b5e770",
            "51ca5ba95a264e82b34cef5c6afa451c",
            "5ff5627a32274b1fbfd709877925d7b8",
            "cd0dc03dc8154b32b64ea960d2a60303",
            "352fecadc6154dd682adbd2d25a8b8c5",
            "d9bdfc34192048028e49a26981980668",
            "cfdede9cff0f4d818a6393832323e09d",
            "8296cd3ab5974d0395a5779fbf92da49"
          ]
        },
        "outputId": "7b21ea7d-dea6-4046-d595-2d275fc7a05d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220727_163625-2usf28nm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2usf28nm\" target=\"_blank\">rural-microwave-7</a></strong> to <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='31.031 MB of 31.031 MB uploaded (30.300 MB deduped)\\r'), FloatProgress(value=1.0, …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "636dea55aa7b4a17b7d01e2d72b5e770"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B sync reduced upload amount by 97.6%             "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">rural-microwave-7</strong>: <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2usf28nm\" target=\"_blank\">https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2usf28nm</a><br/>Synced 4 W&B file(s), 0 media file(s), 102 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220727_163625-2usf28nm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "SPLIT_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"data_split\")\n",
        "\n",
        "SPLIT_COUNTS = BALANCED_SPLITS\n",
        "\n",
        "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
        "data_dir = data_at.download()\n",
        "data_split_at = wandb.Artifact(SPLIT_DATA_AT, type=\"balanced_data\")\n",
        "\n",
        "labels = os.listdir(data_dir)\n",
        "for l in labels:\n",
        "  if l.startswith(\".\"): # skip non-label file\n",
        "    continue\n",
        "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
        "  shuffle(imgs_per_label)\n",
        "  start_id = 0\n",
        "  for split, count in SPLIT_COUNTS.items():\n",
        "    # take a subset\n",
        "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
        "    for img_file in split_imgs:\n",
        "      f_id = img_file.split(\".\")[0]\n",
        "      full_path = os.path.join(data_dir, l, img_file)\n",
        "\n",
        "      data_split_at.add_file(full_path, name = os.path.join(split, l, img_file))\n",
        "    start_id += count\n",
        "\n",
        "# log artifact to W&B\n",
        "run.log_artifact(data_split_at)\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7RBy5ejyoHr"
      },
      "outputs": [],
      "source": [
        "# EXPERIMENT CONFIG\n",
        "#------------------------\n",
        "# Core globals to modify\n",
        "NUM_EPOCHS = 5 # set low for demo purposes, try 3, or 5, or as many as you like\n",
        "\n",
        "\n",
        "# optional globals to modify\n",
        "# set to a custom name to help keep your experiments organized\n",
        "RUN_NAME = \"keras_model_training\" \n",
        "# change this if you'd like start a new set of comparable Tables\n",
        "# (only Tables logged to the same key can be compared)\n",
        "VAL_TABLE_NAME = \"predictions\" \n",
        "\n",
        "# hyperparams set low for demo/training speed\n",
        "# if you set these higher, be mindful of how many items are in\n",
        "# the dataset artifacts you chose by setting the SIZE at the top\n",
        "NUM_TRAIN = BALANCED_SPLITS[\"train\"]*10\n",
        "NUM_VAL = BALANCED_SPLITS[\"val\"]*10\n",
        "\n",
        "# enforced max for this is ceil(NUM_VAL/batch_size)\n",
        "NUM_LOG_BATCHES = 16\n",
        "\n",
        "# ARTIFACTS CONFIG\n",
        "#------------------------\n",
        "# training data artifact to load\n",
        "TRAIN_DATA_AT = PREFIX + \"_80-10-10_\" + str(TOTAL_IMAGES)\n",
        "\n",
        "# model name\n",
        "# if you want to train a sufficiently different model, give this a new name\n",
        "# to start a new lineage for the model, instead of just incrementing the\n",
        "# version of the old model\n",
        "MODEL_NAME = \"iv3_finetuned\"\n",
        "\n",
        "# folder in which to save the final, trained model\n",
        "# if you want to train a sufficiently different model, give this a new name\n",
        "# to start a new lineage for the model, instead of just incrementing the\n",
        "# version of the old model\n",
        "SAVE_MODEL_DIR = \"finetune_iv3_keras\"\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# experiment configuration saved to W&B\n",
        "CFG = {\n",
        "  \"num_train\" : NUM_TRAIN,\n",
        "  \"num_val\" : NUM_VAL,\n",
        "  \"num_classes\" : 10,\n",
        "  \"fc_size\" : 1024,\n",
        "  \"epochs\" : NUM_EPOCHS,\n",
        "  \"batch_size\" : 32,\n",
        "\n",
        "  # inceptionV3 settings\n",
        "  \"img_width\" : 299,\n",
        "  \"img_height\": 299\n",
        "}\n",
        "\n",
        "# number of validation data batches to log/use when computing metrics\n",
        "# at the end of each epoch\n",
        "max_log_batches = int(np.ceil(float(CFG[\"num_val\"])/float(CFG[\"batch_size\"])))\n",
        "# change this min to max to log ALL the available images to a Table\n",
        "CFG[\"num_log_batches\"] = min(max_log_batches, NUM_LOG_BATCHES)\n",
        "\n",
        "def finetune_inception_model(fc_size, num_classes):\n",
        "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
        "  and attach a finetuning top for this classification task\"\"\"\n",
        "  # load InceptionV3 as base\n",
        "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
        "  # freeze base layers\n",
        "  for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "  x = base.get_layer('mixed10').output \n",
        "\n",
        "  # attach a fine-tuning layer\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(fc_size, activation='relu')(x)\n",
        "  guesses = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=base.input, outputs=guesses)\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train():\n",
        "  \"\"\" Main training loop which freezes the InceptionV3 layers of the model\n",
        "  and only trains the new top layers on the new data. A subsequent training\n",
        "  phase might unfreeze all the layers and finetune the whole model on the new data\"\"\" \n",
        "  run = wandb.init(project=PROJECT_NAME, entity=ENTITY, name=RUN_NAME, job_type=\"train\", config=CFG)\n",
        "  cfg = wandb.config\n",
        "\n",
        "  # locate and download training and validation data\n",
        "  data_at = TRAIN_DATA_AT + \":latest\"\n",
        "  data = run.use_artifact(data_at, type=\"balanced_data\")\n",
        "  data_dir = data.download()\n",
        "  train_dir = os.path.join(data_dir, \"train\")\n",
        "  val_dir = os.path.join(data_dir, \"val\")\n",
        "\n",
        "  # create train and validation data generators\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1. / 255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(cfg.img_width, cfg.img_height),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(cfg.img_width, cfg.img_height),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "  # instantiate model and callbacks\n",
        "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
        "  callbacks = [WandbCallback(), ValLog(val_generator, cfg.num_log_batches)]\n",
        "\n",
        "  # train!\n",
        "  model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
        "    epochs=cfg.epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks = callbacks,\n",
        "    validation_steps = cfg.num_val // cfg.batch_size)\n",
        "\n",
        "  \n",
        "  run.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. Train and Checkpoint the Model\n",
        "- Checkpoint the model every epoch and log as a model artifact\n",
        "- Log metrics and predictions"
      ],
      "metadata": {
        "id": "RCatjqmnOjqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ValLog(Callback):\n",
        "  \"\"\" Custom callback to log validation images\n",
        "  at the end of each training epoch\"\"\"\n",
        "  def __init__(self, generator=None, num_log_batches=1):\n",
        "    self.best_loss = float(\"inf\")\n",
        "    self.best_model = None\n",
        "\n",
        "    self.generator = generator\n",
        "    self.num_batches = num_log_batches\n",
        "    # store full names of classes\n",
        "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # collect validation data and ground truth labels from generator\n",
        "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
        "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
        "\n",
        "    # use the trained model to generate predictions for the given number\n",
        "    # of validation data batches (num_batches)\n",
        "    val_preds = self.model.predict(val_data)\n",
        "    true_ids = val_labels.argmax(axis=1)\n",
        "    max_preds = val_preds.argmax(axis=1)\n",
        "\n",
        "    # log validation predictions alongside the run\n",
        "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "    for a in self.flat_class_names:\n",
        "      columns.append(\"score_\" + a)\n",
        "    predictions_table = wandb.Table(columns = columns)\n",
        "    \n",
        "    # log image, predicted and actual labels, and all scores\n",
        "    for filepath, img, top_guess, scores, truth in zip(self.generator.filenames,\n",
        "                                                       val_data, \n",
        "                                                       max_preds, \n",
        "                                                       val_preds,\n",
        "                                                       true_ids):\n",
        "      img_id = filepath.split('/')[-1].split(\".\")[0]\n",
        "      row = [img_id, wandb.Image(img), \n",
        "             self.flat_class_names[top_guess], self.flat_class_names[truth]]\n",
        "      for s in scores.tolist():\n",
        "        row.append(np.round(s, 4))\n",
        "      predictions_table.add_data(*row)\n",
        "\n",
        "    val_acc = np.mean(max_preds == true_ids)\n",
        "    wandb.run.log({VAL_TABLE_NAME : predictions_table,\n",
        "                   'val_acc': val_acc})\n",
        "\n",
        "\n",
        "    is_best = val_acc > self.best_loss\n",
        "    if is_best:\n",
        "        self.best_loss = val_acc\n",
        "    \n",
        "     # Checkpoint the Model at the end of each epoch\n",
        "    trained_model_artifact = wandb.Artifact(\n",
        "              MODEL_NAME, type=\"model\",\n",
        "              description=\"finetuned inception v3\")\n",
        "  \n",
        "    self.model.save(SAVE_MODEL_DIR)\n",
        "    trained_model_artifact.add_dir(SAVE_MODEL_DIR)\n",
        "\n",
        "    # Add an alias indicating the best and latest checkpoint\n",
        "    wandb.log_artifact(trained_model_artifact, aliases=[\"best\", \"latest\"] if is_best else None)\n",
        "    if is_best:\n",
        "        self.best_model = trained_model_artifact"
      ],
      "metadata": {
        "id": "JYwK2_UQD0bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsQ9mCJSyoHt"
      },
      "outputs": [],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. Link the best model checkpoint to the collection\n",
        "1. You can link a model via the UI or api with [wandb.run.link_artifact](https://docs.wandb.ai/guides/models/walkthrough#3.-link-model-versions-to-the-collection)\n",
        "2. Assign a `staging` alias to indicate this model is promising, but still needs further review\n"
      ],
      "metadata": {
        "id": "orPNtn6FOw1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=16FW_aUg7nEaI08tDFGhuX9euaqEfYau1)"
      ],
      "metadata": {
        "id": "rUgJtOeT0PhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_f_adTyoHt"
      },
      "source": [
        "# Step 5. Load your staged model from the collection for evaluation\n",
        "- Perform evaluation and testing on the `staging` model. Refer to it by `Nature Classification:staging`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNF0XNAryoHu"
      },
      "outputs": [],
      "source": [
        "TEST_TABLE_NAME = \"test_results\" \n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"iv3_finetuned\"\n",
        "# location of test data from our original split\n",
        "# should match SPLIT_DATA_AT\n",
        "TEST_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
        "\n",
        "\n",
        "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"inference\")\n",
        "model_at = wandb.use_artifact(\"Nature Classification:staging\")\n",
        "model_dir = model_at.download()\n",
        "print(\"model: \", model_dir)\n",
        "model = keras.models.load_model(model_dir)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# download latest version of test data\n",
        "test_data_at = run.use_artifact(TEST_DATA_AT + \":latest\")\n",
        "test_dir = test_data_at.download()\n",
        "test_dir += \"/test/\"\n",
        "\n",
        "class_names = [\"Animalia\", \"Amphibia\", \"Arachnida\", \"Aves\", \"Fungi\", \n",
        "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
        "\n",
        "# load test images\n",
        "imgs = []\n",
        "filenames = []\n",
        "class_labels = os.listdir(test_dir)\n",
        "truth = []\n",
        "for l in class_labels:\n",
        "  if l.startswith(\".\"):\n",
        "    continue\n",
        "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
        "  for img in imgs_per_class:\n",
        "    # track the image id\n",
        "    filenames.append(img.split(\".\")[0])\n",
        "    truth.append(l)\n",
        "    img_path = os.path.join(test_dir, l, img)\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    img = image.img_to_array(img)\n",
        "    # don't forget to rescale test images to match the range of inputs\n",
        "    # to the network\n",
        "    img = np.expand_dims(img/255.0, axis=0)\n",
        "    imgs.append(img)\n",
        "\n",
        "# predict on test data and bin predictions by guessed label \n",
        "preds = {}\n",
        "imgs = np.vstack(imgs)\n",
        "classes = model.predict(imgs, batch_size=32)\n",
        "for c in classes:\n",
        "  class_id = np.argmax(c)\n",
        "  if class_id in preds:\n",
        "    preds[class_id] += 1\n",
        "  else:\n",
        "    preds[class_id] = 1\n",
        "\n",
        "# log inference results as a Table to the run workspace\n",
        "columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "for a in class_names:\n",
        "  columns.append(\"score_\" + a)\n",
        "test_dt = wandb.Table(columns = columns)\n",
        "\n",
        "# store all the scores for each image\n",
        "for img_id, i, t, c in zip(filenames, imgs, truth, classes):\n",
        "  guess = class_names[np.argmax(c)]\n",
        "  row = [img_id, wandb.Image(i), guess, t]\n",
        "  for c_i in c.tolist():\n",
        "    row.append(np.round(c_i, 4))\n",
        "  test_dt.add_data(*row)\n",
        "  \n",
        "run.log({TEST_TABLE_NAME : test_dt})\n",
        "print(\"Quick distribution of predicted classes: \")\n",
        "print(preds)\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6. Replace Alias\n",
        "- Replace `staging` with `production` alias on the model collection\n",
        "\n",
        "![](https://drive.google.com/uc?id=1W5pRvTAqtjX30r8MZlc3eAkriQMebH8R)\n"
      ],
      "metadata": {
        "id": "7HSFc3-MRefT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Model Registry E2E",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72ad1637f6c944e8a0ecca85ba0b5730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8425455933154828bbf653a29dc5400c",
              "IPY_MODEL_437d1d7dea214f88b05e84fcea131c01"
            ],
            "layout": "IPY_MODEL_0b470a79941c496d96e568e738e18e36"
          }
        },
        "8425455933154828bbf653a29dc5400c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717fac51259b4dce9197ade57b2add7c",
            "placeholder": "​",
            "style": "IPY_MODEL_b5a69e61ef5848af80d7ff054fec742c",
            "value": "0.742 MB of 0.742 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "437d1d7dea214f88b05e84fcea131c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0822b4596474cd98aa2bbffd126c86c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fea4979a0d03432bac5c9c07750e2d7f",
            "value": 1
          }
        },
        "0b470a79941c496d96e568e738e18e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717fac51259b4dce9197ade57b2add7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a69e61ef5848af80d7ff054fec742c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0822b4596474cd98aa2bbffd126c86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea4979a0d03432bac5c9c07750e2d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "636dea55aa7b4a17b7d01e2d72b5e770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51ca5ba95a264e82b34cef5c6afa451c",
              "IPY_MODEL_5ff5627a32274b1fbfd709877925d7b8"
            ],
            "layout": "IPY_MODEL_cd0dc03dc8154b32b64ea960d2a60303"
          }
        },
        "51ca5ba95a264e82b34cef5c6afa451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_352fecadc6154dd682adbd2d25a8b8c5",
            "placeholder": "​",
            "style": "IPY_MODEL_d9bdfc34192048028e49a26981980668",
            "value": "31.044 MB of 31.044 MB uploaded (30.300 MB deduped)\r"
          }
        },
        "5ff5627a32274b1fbfd709877925d7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfdede9cff0f4d818a6393832323e09d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8296cd3ab5974d0395a5779fbf92da49",
            "value": 1
          }
        },
        "cd0dc03dc8154b32b64ea960d2a60303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352fecadc6154dd682adbd2d25a8b8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9bdfc34192048028e49a26981980668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfdede9cff0f4d818a6393832323e09d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8296cd3ab5974d0395a5779fbf92da49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}