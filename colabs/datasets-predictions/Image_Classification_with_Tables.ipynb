{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification with Tables",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf2800fee7e740828023ce98e14f49af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78993254c8a64485931356e12d4e84f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_147ccd283ef547668e9893190581c523",
              "IPY_MODEL_968bd9023bdf444a990ede9a8bf74b30"
            ]
          }
        },
        "78993254c8a64485931356e12d4e84f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "147ccd283ef547668e9893190581c523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_8661d898719043fe82b8f6775d993c3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 301.95MB of 301.95MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d6206e4c47a47938e0dc3a0f8c975b1"
          }
        },
        "968bd9023bdf444a990ede9a8bf74b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94e33fbc554147a88a09d2768273aabe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f2548504f7d425192ab31f8726534df"
          }
        },
        "8661d898719043fe82b8f6775d993c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d6206e4c47a47938e0dc3a0f8c975b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94e33fbc554147a88a09d2768273aabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f2548504f7d425192ab31f8726534df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84aec113943744e3b19ea4278e794d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_503e2e3a85e04fafb8d75565b2f288c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f69e5e22112c48b3a57332530649b772",
              "IPY_MODEL_8b851487444e4476b7cfdf4c6af722c2"
            ]
          }
        },
        "503e2e3a85e04fafb8d75565b2f288c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f69e5e22112c48b3a57332530649b772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_ee3781aa24a84b32be18f5b775e76db0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 302.22MB of 302.22MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be35d3f7bd16489fb8a9f92705be40ba"
          }
        },
        "8b851487444e4476b7cfdf4c6af722c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcd2f222b6e64f2d80db0f20423125cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb074af428a54a49848b5f20d2debbe7"
          }
        },
        "ee3781aa24a84b32be18f5b775e76db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be35d3f7bd16489fb8a9f92705be40ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcd2f222b6e64f2d80db0f20423125cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb074af428a54a49848b5f20d2debbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80e0dc5c758d405ba135515ac4b9ec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3658fa9a9f8a4c6f8e001ad78cb34ea3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4cd8f2e0707a43e1ad48774209047377",
              "IPY_MODEL_e7067b79c6534edea97464f0ccdf5b97"
            ]
          }
        },
        "3658fa9a9f8a4c6f8e001ad78cb34ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cd8f2e0707a43e1ad48774209047377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_38abdcefd99742a682355e13d935c3f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 207.53MB of 207.53MB uploaded (17.24MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af4093597fad45caa7992e8df9c0bdff"
          }
        },
        "e7067b79c6534edea97464f0ccdf5b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8bf1374989dc432e9624a8c7bcddeb5e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37961e38b0aa449191108cfc54e3064b"
          }
        },
        "38abdcefd99742a682355e13d935c3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af4093597fad45caa7992e8df9c0bdff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bf1374989dc432e9624a8c7bcddeb5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37961e38b0aa449191108cfc54e3064b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/Image_Classification_with_Tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCbmQrWI9dku"
      },
      "source": [
        "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "# Image Classification with DSViz\n",
        "\n",
        "This is a walkthrough of [dataset and prediction visualization](https://docs.wandb.com/datasets-and-predictions) (DSViz) and [artifacts](https://docs.wandb.com/artifacts) for image classification on W&B. As an example, I finetune a convnet in Keras on 10,000 photos from  [iNaturalist 2017](https://github.com/visipedia/inat_comp/tree/master/2017) to identify 10 classes of living things (plants, insects, birds, etc). \n",
        "\n",
        "### [See screenshots in this Report](https://wandb.ai/stacey/mendeleev/reports/DSViz-for-Image-Classification--VmlldzozNjE3NjA)\n",
        "\n",
        "## Sign up or login\n",
        "\n",
        "[Sign up or login](https://wandb.ai/login) to W&B to see and interact with your experiments in the browser.\n",
        "\n",
        "In this example we're using Google Colab as a convenient hosted environment, but you can run your own training scripts from anywhere and visualize metrics with W&B's experiment tracking tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4a5JHq9ImF"
      },
      "source": [
        "# Download sample data: Choose 1 of 3 sizes\n",
        "\n",
        "Choose one of the three dataset size options below to run the rest of the demo. With fewer images, you'll run through the demo much faster and use less storage space. With more images, you'll get more realistic model training and more interesting results and examples to explore.\n",
        "\n",
        "Note: **for the largest dataset, this stage might take a few minutes**. If you end up needing to rerun a cell, comment out the first capture line (change ```%%capture``` to ```#%%capture``` ) so you can respond to the prompt about re-downloading the dataset (and see the progress bar).\n",
        "\n",
        "Each zipped directory contains randomly sampled images from the [iNaturalist dataset](https://github.com/visipedia/inat_comp), evenly distributed across 10 classes of living things like birds, insects, plants, and mammals (names given in Latin—so Aves, Insecta, Plantae, etc :). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtS_LE9371oD"
      },
      "source": [
        "# set SIZE to \"TINY\", \"MEDIUM\", or \"LARGE\"\n",
        "# to select one of these three datasets\n",
        "# TINY dataset: 100 images, 30MB\n",
        "# MEDIUM dataset: 1000 images, 312MB\n",
        "# LARGE dataset: 12,000 images, 3.6GB\n",
        "\n",
        "SIZE = \"MEDIUM\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dkrm52V9PQm"
      },
      "source": [
        "if SIZE == \"TINY\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
        "  src_zip = \"nature_100.zip\"\n",
        "  DATA_SRC = \"nature_100\"\n",
        "  IMAGES_PER_LABEL = 10\n",
        "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
        "elif SIZE == \"MEDIUM\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
        "  src_zip = \"nature_1K.zip\"\n",
        "  DATA_SRC = \"nature_1K\"\n",
        "  IMAGES_PER_LABEL = 100\n",
        "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
        "elif SIZE == \"LARGE\":\n",
        "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "  src_zip = \"nature_12K.zip\"\n",
        "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
        "  IMAGES_PER_LABEL = 1000\n",
        "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm-nAO0tAEOO"
      },
      "source": [
        "%%capture\n",
        "!curl -SL $src_url > $src_zip\n",
        "!unzip $src_zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukX2ptqLfgOj"
      },
      "source": [
        "# Step 0: Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haJFhFkjyzkq"
      },
      "source": [
        "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
        "\n",
        "\n",
        "*   **pip install wandb** – Install the W&B library\n",
        "*   **import wandb** – Import the wandb library\n",
        "*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsueEW0Zdovz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f64d2dee-71b6-410a-8dbb-63c02fe74dae"
      },
      "source": [
        "!pip install wandb -qq\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 50.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-6OyLBlDTM_"
      },
      "source": [
        "import os\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# source directory for all raw data\n",
        "SRC = DATA_SRC\n",
        "PREFIX = \"inat\" # convenient for tracking local data\n",
        "PROJECT_NAME = \"tables_demo\"\n",
        "\n",
        "# number of images per class label\n",
        "# the total number of images is 10X this (10 classes)\n",
        "TOTAL_IMAGES = IMAGES_PER_LABEL * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UOxx2oPB-PN"
      },
      "source": [
        "# Step 1: Upload raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W8Dnxpoaxz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "cf2800fee7e740828023ce98e14f49af",
            "78993254c8a64485931356e12d4e84f9",
            "147ccd283ef547668e9893190581c523",
            "968bd9023bdf444a990ede9a8bf74b30",
            "8661d898719043fe82b8f6775d993c3e",
            "7d6206e4c47a47938e0dc3a0f8c975b1",
            "94e33fbc554147a88a09d2768273aabe",
            "2f2548504f7d425192ab31f8726534df"
          ]
        },
        "outputId": "cec37ecd-b549-4867-dee4-6566c28f874d"
      },
      "source": [
        "# if this is a substantially new dataset, give it a new name\n",
        "# this will create a whole new placeholder (Artifact) for this dataset\n",
        "# instead of just incrementing a version of the old dataset\n",
        "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, job_type=\"upload\")\n",
        "# create an artifact for all the raw data\n",
        "raw_data_at = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
        "\n",
        "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
        "# each folder contains images of the corresponding class\n",
        "labels = os.listdir(SRC)\n",
        "for l in labels:\n",
        "  imgs_per_label = os.path.join(SRC, l)\n",
        "  if os.path.isdir(imgs_per_label):\n",
        "    # filter out \"DS_Store\"\n",
        "    imgs = [i for i in os.listdir(imgs_per_label) if not i.startswith(\".DS\")]\n",
        "    # randomize the order\n",
        "    shuffle(imgs)\n",
        "    img_file_ids = imgs[:IMAGES_PER_LABEL]\n",
        "    for f in img_file_ids:\n",
        "      file_path = os.path.join(SRC, l, f)\n",
        "      # add file to artifact by full path\n",
        "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
        "\n",
        "# save artifact to W&B\n",
        "run.log_artifact(raw_data_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstacey\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">zany-dawn-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stacey/tables_demo\" target=\"_blank\">https://wandb.ai/stacey/tables_demo</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stacey/tables_demo/runs/1gkygmzb\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/1gkygmzb</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210709_212013-1gkygmzb</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 142<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf2800fee7e740828023ce98e14f49af",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 301.94MB of 301.94MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210709_212013-1gkygmzb/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210709_212013-1gkygmzb/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 1002 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">zany-dawn-1</strong>: <a href=\"https://wandb.ai/stacey/tables_demo/runs/1gkygmzb\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/1gkygmzb</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZqZ9WxRIj2c"
      },
      "source": [
        "![img](https://i.imgur.com/EjVjKuL.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGyh9hwYPkQe"
      },
      "source": [
        "# Step 2: Split raw data to prepare for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4O-Kf4Kx7Xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "84aec113943744e3b19ea4278e794d92",
            "503e2e3a85e04fafb8d75565b2f288c7",
            "f69e5e22112c48b3a57332530649b772",
            "8b851487444e4476b7cfdf4c6af722c2",
            "ee3781aa24a84b32be18f5b775e76db0",
            "be35d3f7bd16489fb8a9f92705be40ba",
            "bcd2f222b6e64f2d80db0f20423125cc",
            "fb074af428a54a49848b5f20d2debbe7"
          ]
        },
        "outputId": "8c86414f-c2b2-4a1b-ad8b-1a884f19b352"
      },
      "source": [
        "# if this is a substantially different dataset, give it a new name\n",
        "# this will create a whole new placeholder (Artifact) for this split\n",
        "# instead of just incrementing a version of the old data split\n",
        "SPLIT_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
        "run = wandb.init(project=PROJECT_NAME, job_type=\"data_split\")\n",
        "\n",
        "# create balanced train, val, test splits\n",
        "# each count is the number of images per label\n",
        "SPLIT_COUNTS = BALANCED_SPLITS\n",
        "\n",
        "# find the most recent (\"latest\") version of the full raw data\n",
        "# you can of course pass around programmatic aliases and not string literals\n",
        "# note: RAW_DATA_AT is defined in the previous cell—if you're running\n",
        "# just this step, you may need to hardcode it\n",
        "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
        "# download it locally (for illustration purposes/across hardware; you can\n",
        "# also sync/version artifacts by reference)\n",
        "data_dir = data_at.download()\n",
        "\n",
        "data_split_at = wandb.Artifact(SPLIT_DATA_AT, type=\"balanced_data\")\n",
        "\n",
        "# create a table with columns we want to track/compare\n",
        "preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\", \"split\"])\n",
        "\n",
        "labels = os.listdir(data_dir)\n",
        "for l in labels:\n",
        "  if l.startswith(\".\"): # skip non-label file\n",
        "    continue\n",
        "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
        "  shuffle(imgs_per_label)\n",
        "  start_id = 0\n",
        "  for split, count in SPLIT_COUNTS.items():\n",
        "    # take a subset\n",
        "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
        "    for img_file in split_imgs:\n",
        "      f_id = img_file.split(\".\")[0]\n",
        "      full_path = os.path.join(data_dir, l, img_file)\n",
        "      # add file to artifact by full path\n",
        "      # note: pass the label to the name parameter to retain it in\n",
        "      # the data structure \n",
        "      data_split_at.add_file(full_path, name = os.path.join(split, l, img_file))\n",
        "      # add a preview of the image\n",
        "      if split != \"test\":\n",
        "        preview_dt.add_data(f_id, wandb.Image(full_path), l, split)\n",
        "      else:\n",
        "        # pretend we have unlabeled test data\n",
        "        # (replace \"unknown\" with l if you'd like to keep the labels :)\n",
        "        preview_dt.add_data(f_id, wandb.Image(full_path), \"unknown\", split)\n",
        "    start_id += count\n",
        "\n",
        "# log artifact to W&B\n",
        "data_split_at.add(preview_dt, \"data_split\")\n",
        "run.log_artifact(data_split_at)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">proud-music-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stacey/tables_demo\" target=\"_blank\">https://wandb.ai/stacey/tables_demo</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stacey/tables_demo/runs/2qixk7p1\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/2qixk7p1</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210709_212120-2qixk7p1</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact inat_raw_data_1000:latest, 301.91MB. 1000 files... Done. 0:0:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 1189<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84aec113943744e3b19ea4278e794d92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 302.21MB of 302.21MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210709_212120-2qixk7p1/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210709_212120-2qixk7p1/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 1003 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">proud-music-2</strong>: <a href=\"https://wandb.ai/stacey/tables_demo/runs/2qixk7p1\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/2qixk7p1</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODZZ_DdPepbI"
      },
      "source": [
        "# NOTE: if this Colab is running out of RAM, try running this cell\n",
        "del data_split_at\n",
        "del preview_dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aO05N3DGfhW"
      },
      "source": [
        "# Step 3: Train with artifacts and save model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJroq2t8DHWW"
      },
      "source": [
        "# EXPERIMENT CONFIG\n",
        "#------------------------\n",
        "# Core globals to modify\n",
        "NUM_EPOCHS = 3 # set low for demo purposes, try 3, 5, or as many as you like\n",
        "\n",
        "# optional globals to modify\n",
        "# set to a custom name to help keep your experiments organized\n",
        "RUN_NAME = \"\" \n",
        "# change this if you'd like start a new set of comparable Tables\n",
        "# (only Tables logged to the same key can be compared)\n",
        "VAL_TABLE_NAME = \"predictions\" \n",
        "\n",
        "# hyperparams set low for demo/training speed\n",
        "# if you set these higher, be mindful of how many items are in\n",
        "# the dataset artifacts you chose by setting the SIZE at the top\n",
        "NUM_TRAIN = BALANCED_SPLITS[\"train\"]*10\n",
        "NUM_VAL = BALANCED_SPLITS[\"val\"]*10\n",
        "\n",
        "# ARTIFACTS CONFIG\n",
        "#------------------------\n",
        "# training data artifact to load\n",
        "TRAIN_DATA_AT = PREFIX + \"_80-10-10_\" + str(TOTAL_IMAGES)\n",
        "\n",
        "# model name & folder in which to save the trained model\n",
        "# if you want to train a sufficiently different model, give these new names\n",
        "# to start a new lineage for the model, instead of just incrementing the\n",
        "# version of the old model\n",
        "MODEL_NAME = \"iv3_baseline\"\n",
        "MODEL_DIR = \"iv3_baseline_model\"\n",
        "\n",
        "# enforced max for this is ceil(NUM_VAL/batch_size)\n",
        "NUM_LOG_BATCHES = 16\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# experiment configuration saved to W&B\n",
        "CFG = {\n",
        "  \"num_train\" : NUM_TRAIN,\n",
        "  \"num_val\" : NUM_VAL,\n",
        "  \"num_classes\" : 10,\n",
        "  \"fc_size\" : 512,\n",
        "  \"epochs\" : NUM_EPOCHS,\n",
        "  \"batch_size\" : 32,\n",
        "\n",
        "  # inceptionV3 settings\n",
        "  \"img_width\" : 299,\n",
        "  \"img_height\": 299\n",
        "}\n",
        "\n",
        "# number of validation data batches to log/use when computing metrics\n",
        "# at the end of each epoch\n",
        "max_log_batches = int(np.ceil(float(CFG[\"num_val\"])/float(CFG[\"batch_size\"])))\n",
        "CFG[\"num_log_batches\"] = min(max_log_batches, NUM_LOG_BATCHES)\n",
        "\n",
        "def finetune_inception_model(fc_size, num_classes):\n",
        "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
        "  and attach a finetuning top for this classification task\"\"\"\n",
        "  # load InceptionV3 as base\n",
        "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
        "  # freeze base layers\n",
        "  for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "  x = base.get_layer('mixed10').output \n",
        "\n",
        "  # attach a fine-tuning layer\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(fc_size, activation='relu')(x)\n",
        "  guesses = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=base.input, outputs=guesses)\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def train():\n",
        "  \"\"\" Main training loop which freezes the InceptionV3 layers of the model\n",
        "  and only trains the new top layers on the new data. A subsequent training\n",
        "  phase might unfreeze all the layers and finetune the whole model on the new data\"\"\" \n",
        "  run = wandb.init(project=PROJECT_NAME, job_type=\"train\", name=RUN_NAME, config=CFG)\n",
        "  cfg = wandb.config\n",
        "\n",
        "  # locate and download training and validation data\n",
        "  data_at = TRAIN_DATA_AT + \":latest\"\n",
        "  data = run.use_artifact(data_at, type=\"balanced_data\")\n",
        "  data_dir = data.download()\n",
        "  train_dir = os.path.join(data_dir, \"train\")\n",
        "  val_dir = os.path.join(data_dir, \"val\")\n",
        "\n",
        "  # create train and validation data generators\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1. / 255,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True)\n",
        "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(cfg.img_width, cfg.img_height),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "  val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(cfg.img_width, cfg.img_height),\n",
        "    batch_size=cfg.batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "  # instantiate model and callbacks\n",
        "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
        "  callbacks = [WandbCallback(), ValLog(val_generator, cfg.num_log_batches)]\n",
        "\n",
        "  # train!\n",
        "  model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
        "    epochs=cfg.epochs,\n",
        "    validation_data=val_generator,\n",
        "    callbacks = callbacks,\n",
        "    validation_steps = cfg.num_val // cfg.batch_size)\n",
        "\n",
        "  # save trained model as artifact\n",
        "  trained_model_artifact = wandb.Artifact(\n",
        "            MODEL_NAME, type=\"model\",\n",
        "            description=\"finetuned inception v3\",\n",
        "            metadata=dict(cfg))\n",
        "  \n",
        "  model.save(MODEL_DIR)\n",
        "  trained_model_artifact.add_dir(MODEL_DIR)\n",
        "  run.log_artifact(trained_model_artifact)\n",
        "  run.finish()\n",
        "\n",
        "class ValLog(Callback):\n",
        "  \"\"\" Custom callback to log validation images\n",
        "  at the end of each training epoch\"\"\"\n",
        "  def __init__(self, generator=None, num_log_batches=1):\n",
        "    self.generator = generator\n",
        "    self.num_batches = num_log_batches\n",
        "    # store full names of classes\n",
        "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # collect validation data and ground truth labels from generator\n",
        "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
        "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
        "\n",
        "    # use the trained model to generate predictions for the given number\n",
        "    # of validation data batches (num_batches)\n",
        "    val_preds = self.model.predict(val_data)\n",
        "    true_ids = val_labels.argmax(axis=1)\n",
        "    max_preds = val_preds.argmax(axis=1)\n",
        "\n",
        "    # log validation predictions alongside the run\n",
        "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "    for a in self.flat_class_names:\n",
        "      columns.append(\"score_\" + a)\n",
        "    predictions_table = wandb.Table(columns = columns)\n",
        "    \n",
        "    # log image, predicted and actual labels, and all scores\n",
        "    for filepath, img, top_guess, scores, truth in zip(self.generator.filenames,\n",
        "                                                       val_data, \n",
        "                                                       max_preds, \n",
        "                                                       val_preds,\n",
        "                                                       true_ids):\n",
        "      img_id = filepath.split('/')[-1].split(\".\")[0]\n",
        "      row = [img_id, wandb.Image(img), \n",
        "             self.flat_class_names[top_guess], self.flat_class_names[truth]]\n",
        "      for s in scores.tolist():\n",
        "        row.append(np.round(s, 4))\n",
        "      predictions_table.add_data(*row)\n",
        "    wandb.run.log({VAL_TABLE_NAME : predictions_table})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z4gV9vYDoOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976,
          "referenced_widgets": [
            "80e0dc5c758d405ba135515ac4b9ec85",
            "3658fa9a9f8a4c6f8e001ad78cb34ea3",
            "4cd8f2e0707a43e1ad48774209047377",
            "e7067b79c6534edea97464f0ccdf5b97",
            "38abdcefd99742a682355e13d935c3f3",
            "af4093597fad45caa7992e8df9c0bdff",
            "8bf1374989dc432e9624a8c7bcddeb5e",
            "37961e38b0aa449191108cfc54e3064b"
          ]
        },
        "outputId": "f53d4aca-a899-47dc-ebab-358fa1ce22d9"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fc 512</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/stacey/tables_demo\" target=\"_blank\">https://wandb.ai/stacey/tables_demo</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/stacey/tables_demo/runs/132cr30w\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/132cr30w</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210709_212843-132cr30w</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact inat_80-10-10_1000:latest, 302.16MB. 1001 files... Done. 0:0:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 10 classes.\n",
            "Found 100 images belonging to 10 classes.\n",
            "Epoch 1/3\n",
            "25/25 [==============================] - 27s 960ms/step - loss: 2.5683 - accuracy: 0.4075 - val_loss: 1.3626 - val_accuracy: 0.6562\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 23s 899ms/step - loss: 1.2105 - accuracy: 0.6475 - val_loss: 1.3709 - val_accuracy: 0.5938\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 23s 907ms/step - loss: 0.9318 - accuracy: 0.7513 - val_loss: 1.0463 - val_accuracy: 0.7188\n",
            "INFO:tensorflow:Assets written to: trained_keras_model_iv3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained_keras_model_iv3)... Done. 2.4s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 2796<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80e0dc5c758d405ba135515ac4b9ec85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 207.50MB of 207.50MB uploaded (17.24MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210709_212843-132cr30w/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210709_212843-132cr30w/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.93185</td></tr><tr><td>accuracy</td><td>0.75125</td></tr><tr><td>val_loss</td><td>1.04633</td></tr><tr><td>val_accuracy</td><td>0.71875</td></tr><tr><td>_runtime</td><td>103</td></tr><tr><td>_timestamp</td><td>1625866226</td></tr><tr><td>_step</td><td>5</td></tr><tr><td>best_val_loss</td><td>1.04633</td></tr><tr><td>best_epoch</td><td>2</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▂▁</td></tr><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>val_loss</td><td>██▁</td></tr><tr><td>val_accuracy</td><td>▅▁█</td></tr><tr><td>_runtime</td><td>▁▂▄▅▇█</td></tr><tr><td>_timestamp</td><td>▁▂▄▅▇█</td></tr><tr><td>_step</td><td>▁▂▄▅▇█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 4 media file(s), 109 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fc 512</strong>: <a href=\"https://wandb.ai/stacey/tables_demo/runs/132cr30w\" target=\"_blank\">https://wandb.ai/stacey/tables_demo/runs/132cr30w</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQSbnaDiB8hB"
      },
      "source": [
        "# Step 4: Load model for inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swH5i22yUxVw"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"iv3_baseline\"\n",
        "\n",
        "# location of test data from our original split\n",
        "# should match SPLIT_DATA_AT\n",
        "TEST_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
        "\n",
        "# optional globals to modify\n",
        "# set to a custom name to help keep your experiments organized\n",
        "RUN_NAME = \"\" \n",
        "RUN_NAME = \"\"\n",
        "# change this if you'd like start a new set of comparable Tables\n",
        "# (only Tables logged to the same key can be compared)\n",
        "TEST_TABLE_NAME = \"test_results\" \n",
        "\n",
        "run = wandb.init(project=PROJECT_NAME, job_type=\"inference\", name=RUN_NAME)\n",
        "model_at = run.use_artifact(MODEL_NAME + \":latest\")\n",
        "model_dir = model_at.download()\n",
        "print(\"model: \", model_dir)\n",
        "model = keras.models.load_model(model_dir)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# download latest version of test data\n",
        "test_data_at = run.use_artifact(TEST_DATA_AT + \":latest\")\n",
        "test_dir = test_data_at.download()\n",
        "test_dir += \"/test/\"\n",
        "\n",
        "class_names = [\"Animalia\", \"Amphibia\", \"Arachnida\", \"Aves\", \"Fungi\", \n",
        "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
        "\n",
        "# load test images\n",
        "imgs = []\n",
        "filenames = []\n",
        "class_labels = os.listdir(test_dir)\n",
        "truth = []\n",
        "for l in class_labels:\n",
        "  if l.startswith(\".\"):\n",
        "    continue\n",
        "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
        "  for img in imgs_per_class:\n",
        "    # track the image id\n",
        "    filenames.append(img.split(\".\")[0])\n",
        "    truth.append(l)\n",
        "    img_path = os.path.join(test_dir, l, img)\n",
        "    img = image.load_img(img_path, target_size=(299, 299))\n",
        "    img = image.img_to_array(img)\n",
        "    # don't forget to rescale test images to match the range of inputs\n",
        "    # to the network\n",
        "    img = np.expand_dims(img/255.0, axis=0)\n",
        "    imgs.append(img)\n",
        "\n",
        "# predict on test data and bin predictions by guessed label \n",
        "preds = {}\n",
        "imgs = np.vstack(imgs)\n",
        "classes = model.predict(imgs, batch_size=32)\n",
        "for c in classes:\n",
        "  class_id = np.argmax(c)\n",
        "  if class_id in preds:\n",
        "    preds[class_id] += 1\n",
        "  else:\n",
        "    preds[class_id] = 1\n",
        "\n",
        "# log test results to run workspace\n",
        "columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "for a in class_names:\n",
        "  columns.append(\"score_\" + a)\n",
        "test_dt = wandb.Table(columns = columns)\n",
        "\n",
        "# store all the scores for each image\n",
        "for img_id, i, t, c in zip(filenames, imgs, truth, classes):\n",
        "  guess = class_names[np.argmax(c)]\n",
        "  row = [img_id, wandb.Image(i), guess, t]\n",
        "  for c_i in c.tolist():\n",
        "    row.append(np.round(c_i, 4))\n",
        "  test_dt.add_data(*row)\n",
        "  \n",
        "run.log({TEST_TABLE_NAME : test_dt})\n",
        "print(\"Quick distribution of predicted classes: \")\n",
        "print(preds)\n",
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43mWDdCzZZeH"
      },
      "source": [
        "# More about Weights & Biases\n",
        "We're always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions. Here are some more resources:\n",
        "\n",
        "1. [Documentation](http://docs.wandb.com) - Python docs\n",
        "2. [Gallery](https://app.wandb.ai/gallery) - example reports in W&B\n",
        "3. [Articles](https://www.wandb.com/articles) - blog posts and tutorials\n",
        "4. [Community](wandb.me/slack) - join our Slack community forum"
      ]
    }
  ]
}