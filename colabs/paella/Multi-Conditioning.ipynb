{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb35d29d-ecec-4917-b876-f65b7e8def5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "import open_clip\n",
    "from rudalle import get_vae\n",
    "from einops import rearrange\n",
    "from open_clip import tokenizer\n",
    "\n",
    "from Paella.modules import DenoiseUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23328f6-12f2-498c-9322-803c67f2a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeekyrakshit\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20221118_080131-3elky2is</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/geekyrakshit/paella/runs/3elky2is\" target=\"_blank\">smart-eon-34</a></strong> to <a href=\"https://wandb.ai/geekyrakshit/paella\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"paella\", entity=\"geekyrakshit\", job_type=\"multi-conditioning\")\n",
    "\n",
    "\n",
    "config = wandb.config\n",
    "config.text_model_artifact = \"geekyrakshit/paella/text-model:v0\"\n",
    "config.image_model_artifact = \"geekyrakshit/paella/fine-tuned-image-model:v0\"\n",
    "config.seed = 42\n",
    "config.batch_size = 4\n",
    "config.latent_shape = (32, 100)\n",
    "config.conditions = [\n",
    "    [\"an oil painting of a lighthouse standing on a hill\", 20],\n",
    "    [\"an oil painting of a majestic boat sailing on the water during a storm. front view\", 60],\n",
    "    [\"an oil painting of a majestic winged horse with front legs raised standing by the water\", 100],\n",
    "]\n",
    "config.clip_embedding_dim = 1024\n",
    "\n",
    "# Seed Everything\n",
    "torch.manual_seed(config.seed)\n",
    "torch.random.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed(config.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedf7c83-e685-4da0-948d-29b2f7f88bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact text-model:v0, 2205.13MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact fine-tuned-image-model:v0, 2205.13MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.1\n"
     ]
    }
   ],
   "source": [
    "text_model_path = os.path.join(wandb.use_artifact(\n",
    "    config.text_model_artifact, type='model'\n",
    ").download(), \"model_600000.pt\")\n",
    "image_model_path = os.path.join(wandb.use_artifact(\n",
    "    config.image_model_artifact, type='model'\n",
    ").download(), \"model_50000_img.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4693a9b6-950f-45bc-b08c-1075bf8abe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172af2c6-3440-4cbb-8dc2-88f95d0ea9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_multi_conditioning_results(images):\n",
    "    images = [wandb.Image(image) for image in (images.cpu().numpy() * 255.0).astype(np.uint8)]\n",
    "    table = wandb.Table(columns=[\"Seed\", \"Prompts\", \"End-Token-Positions\", \"Latent-Shape\", \"Generated-Images\"])\n",
    "    table.add_data(\n",
    "        config.seed,\n",
    "        [condition[0] for condition in config.conditions],\n",
    "        [condition[1] for condition in config.conditions],\n",
    "        config.latent_shape,\n",
    "        images\n",
    "    )\n",
    "    wandb.log({\"Multi-Conditioning-Results\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff68bc9-8fc2-449d-994b-9642669f8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(t, eps=1e-20):\n",
    "    return torch.log(t + eps)\n",
    "\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "\n",
    "def gumbel_sample(t, temperature=1., dim=-1):\n",
    "    return ((t / max(temperature, 1e-10)) + gumbel_noise(t)).argmax(dim=dim)\n",
    "\n",
    "def sample(\n",
    "    model, c, x=None, mask=None, T=12, size=(32, 32),\n",
    "    starting_t=0, temp_range=[1.0, 1.0], typical_filtering=True,\n",
    "    typical_mass=0.2, typical_min_tokens=1, classifier_free_scale=-1,\n",
    "    renoise_steps=11, renoise_mode='start'\n",
    "):\n",
    "    with torch.inference_mode():\n",
    "        r_range = torch.linspace(0, 1, T+1)[:-1][:, None].expand(-1, c.size(0)).to(c.device)\n",
    "        temperatures = torch.linspace(temp_range[0], temp_range[1], T)\n",
    "        preds = []\n",
    "        if x is None:\n",
    "            x = torch.randint(0, model.num_labels, size=(c.size(0), *size), device=c.device)\n",
    "        elif mask is not None:\n",
    "            noise = torch.randint(0, model.num_labels, size=(c.size(0), *size), device=c.device)\n",
    "            x = noise * mask + (1-mask) * x\n",
    "        init_x = x.clone()\n",
    "        for i in range(starting_t, T):\n",
    "            if renoise_mode == 'prev':\n",
    "                prev_x = x.clone()\n",
    "            r, temp = r_range[i], temperatures[i]\n",
    "            logits = model(x, c, r)\n",
    "            if classifier_free_scale >= 0:\n",
    "                logits_uncond = model(x, torch.zeros_like(c), r)\n",
    "                logits = torch.lerp(logits_uncond, logits, classifier_free_scale)\n",
    "            x = logits\n",
    "            x_flat = x.permute(0, 2, 3, 1).reshape(-1, x.size(1))\n",
    "            if typical_filtering:\n",
    "                x_flat_norm = torch.nn.functional.log_softmax(x_flat, dim=-1)\n",
    "                x_flat_norm_p = torch.exp(x_flat_norm)\n",
    "                entropy = -(x_flat_norm * x_flat_norm_p).nansum(-1, keepdim=True)\n",
    "\n",
    "                c_flat_shifted = torch.abs((-x_flat_norm) - entropy)\n",
    "                c_flat_sorted, x_flat_indices = torch.sort(c_flat_shifted, descending=False)\n",
    "                x_flat_cumsum = x_flat.gather(-1, x_flat_indices).softmax(dim=-1).cumsum(dim=-1)\n",
    "\n",
    "                last_ind = (x_flat_cumsum < typical_mass).sum(dim=-1)\n",
    "                sorted_indices_to_remove = c_flat_sorted > c_flat_sorted.gather(1, last_ind.view(-1, 1))\n",
    "                if typical_min_tokens > 1:\n",
    "                    sorted_indices_to_remove[..., :typical_min_tokens] = 0\n",
    "                indices_to_remove = sorted_indices_to_remove.scatter(1, x_flat_indices, sorted_indices_to_remove)\n",
    "                x_flat = x_flat.masked_fill(indices_to_remove, -float(\"Inf\"))\n",
    "            # x_flat = torch.multinomial(x_flat.div(temp).softmax(-1), num_samples=1)[:, 0]\n",
    "            x_flat = gumbel_sample(x_flat, temperature=temp)\n",
    "            x = x_flat.view(x.size(0), *x.shape[2:])\n",
    "            if mask is not None:\n",
    "                x = x * mask + (1-mask) * init_x\n",
    "            if i < renoise_steps:\n",
    "                if renoise_mode == 'start':\n",
    "                    x, _ = model.add_noise(x, r_range[i+1], random_x=init_x)\n",
    "                elif renoise_mode == 'prev':\n",
    "                    x, _ = model.add_noise(x, r_range[i+1], random_x=prev_x)\n",
    "                else: # 'rand'\n",
    "                    x, _ = model.add_noise(x, r_range[i+1])\n",
    "            preds.append(x.detach())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27874a53-1e32-4206-b64f-05e58fba45ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 32, 32) = 262144 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/huggingface_hub/file_download.py:595: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae --> ready\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vqmodel = get_vae().to(device)\n",
    "vqmodel.eval().requires_grad_(False)\n",
    "\n",
    "clip_model, _, _ = open_clip.create_model_and_transforms('ViT-g-14', pretrained='laion2b_s12b_b42k')\n",
    "clip_model = clip_model.to(device).eval().requires_grad_(False)\n",
    "\n",
    "\n",
    "def encode(x):\n",
    "    return vqmodel.model.encode((2 * x - 1))[-1][-1]\n",
    "    \n",
    "def decode(img_seq, shape=(32,32)):\n",
    "        img_seq = img_seq.view(img_seq.shape[0], -1)\n",
    "        b, n = img_seq.shape\n",
    "        one_hot_indices = torch.nn.functional.one_hot(img_seq, num_classes=vqmodel.num_tokens).float()\n",
    "        z = (one_hot_indices @ vqmodel.model.quantize.embed.weight)\n",
    "        z = rearrange(z, 'b (h w) c -> b c h w', h=shape[0], w=shape[1])\n",
    "        img = vqmodel.model.decode(z)\n",
    "        img = (img.clamp(-1., 1.) + 1) * 0.5\n",
    "        return img\n",
    "    \n",
    "state_dict = torch.load(text_model_path, map_location=device)\n",
    "model = DenoiseUNet(num_labels=8192).to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval().requires_grad_()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3753c2be-cbce-4292-b73f-2701a8ad99c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26512fb6924f3a8d57a78c7066e824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip_embedding = torch.zeros(\n",
    "    config.batch_size,\n",
    "    config.clip_embedding_dim,\n",
    "    *config.latent_shape\n",
    ").to(device)\n",
    "\n",
    "last_pos = 0\n",
    "for text, pos in tqdm(config.conditions):\n",
    "    tokenized_text = tokenizer.tokenize([text] * config.batch_size).to(device)\n",
    "    part_clip_embedding = clip_model.encode_text(tokenized_text).float()[:, :, None, None]\n",
    "    clip_embedding[:, :, :, last_pos:pos] = part_clip_embedding\n",
    "    last_pos = pos\n",
    "with torch.inference_mode():\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        s = time.time()\n",
    "        sampled = sample(\n",
    "            model, clip_embedding, T=12, size=config.latent_shape, starting_t=0,\n",
    "            temp_range=[1.0, 1.0], typical_filtering=True, typical_mass=0.2,\n",
    "            typical_min_tokens=1, classifier_free_scale=5, renoise_steps=11, renoise_mode=\"start\"\n",
    "        )\n",
    "        wandb.log({\"Sampling-Time\": time.time() - s})\n",
    "    sampled = decode(sampled[-1], config.latent_shape).permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc9c8431-6068-4961-bc01-f128b1d88fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c9e816883742bebc3dd2c996882f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.197 MB of 1.197 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Sampling-Time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Sampling-Time</td><td>5.38642</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">smart-eon-34</strong>: <a href=\"https://wandb.ai/geekyrakshit/paella/runs/3elky2is\" target=\"_blank\">https://wandb.ai/geekyrakshit/paella/runs/3elky2is</a><br/>Synced 6 W&B file(s), 1 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221118_080131-3elky2is/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_multi_conditioning_results(sampled)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a90d54-7717-402f-9086-ea40c1866adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
