{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/diffusers/lcm-diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{lcm-diffusers-colab} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation with Consistency Models using ðŸ¤— Diffusers\n",
    "\n",
    "<!--- @wandbcode{lcm-diffusers-colab} -->\n",
    "\n",
    "This notebook demonstrates the following:\n",
    "- Performing text-conditional image-generations with the [Consistency Models](https://huggingface.co/docs/diffusers/api/pipelines/consistency_models) using [ðŸ¤— Diffusers](https://huggingface.co/docs/diffusers).\n",
    "- Manage image generation experiments using [Weights & Biases](http://wandb.ai/site).\n",
    "- Log the prompts, generated images and experiment configs to [Weigts & Biases](http://wandb.ai/site) for visalization.\n",
    "\n",
    "![](./assets/diffusers-autolog-4.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers transformers accelerate wandb > install.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.diffusers import autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the diffusion pipeline for latent consistency model\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"SimianLuo/LCM_Dreamshaper_v7\")\n",
    "pipeline = pipeline.to(torch_device=\"cuda\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompts, negative prompts, and seed.\n",
    "prompt = [\n",
    "    \"a photograph of an astronaut riding a horse\",\n",
    "    \"a photograph of a dragon\"\n",
    "]\n",
    "\n",
    "# Make the experiment reproducible by controlling randomness.\n",
    "# The seed would be automatically logged to WandB.\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call WandB Autolog for Diffusers. This would automatically log\n",
    "# the prompts, generated images, pipeline architecture and all\n",
    "# associated experiment configs to Weights & Biases, thus making your\n",
    "# image generation experiments easy to reproduce, share and analyze.\n",
    "autolog(init=dict(project=\"diffusers_logging\"))\n",
    "\n",
    "# call the pipeline to generate the images\n",
    "images = pipeline(\n",
    "    prompt,\n",
    "    num_images_per_prompt=2,\n",
    "    generator=generator,\n",
    "    num_inference_steps=10,\n",
    ")\n",
    "\n",
    "# End the experiment\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
