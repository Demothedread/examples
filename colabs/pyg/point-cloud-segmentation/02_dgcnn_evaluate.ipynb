{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pyg/point-cloud-segmentation/02_dgcnn_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{pyg-dgcnn-eval} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9385afd2-4e70-4fc3-820b-576bdf035e42",
   "metadata": {},
   "source": [
    "# üî•üî• Evaluate DGCNN Model Weights & Biases ü™Ñüêù\n",
    "\n",
    "<!--- @wandbcode{pyg-dgcnn-eval} -->\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/examples/blob/pyg/point-cloud-segmentation/colabs/pyg/point-cloud-segmentation/02_dgcnn_evaluate.ipynb)\n",
    "\n",
    "This notebook demonstrates the evaluation of [Dynamic Graph CNN](https://arxiv.org/pdf/1801.07829.pdf) for point cloud segmnetation. You can check the following notebook for referring to the training code:\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/examples/blob/pyg/point-cloud-segmentation/colabs/pyg/point-cloud-segmentation/01_dgcnn_train.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79b763-e197-4a1d-9f3f-f89d873c12ed",
   "metadata": {},
   "source": [
    "# Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46eac0-9bf8-4c3b-906a-ca56343810ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a87ef2-abf9-4d71-a4ae-d58e3ebba706",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f5a6e-fedd-48ef-9861-66e8ffb9fbbd",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cf4d8-6839-47fb-b789-857997e15107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_scatter import scatter\n",
    "from torchmetrics.functional import jaccard_index\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, DynamicEdgeConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643258d-84be-4a10-a67e-0cf0331e07aa",
   "metadata": {},
   "source": [
    "# Initialize Weights & Biases\n",
    "\n",
    "We need to call [`wandb.init()`](https://docs.wandb.ai/ref/python/init) once at the beginning of our program to initialize a new job. This creates a new run in W&B and launches a background process to sync data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fec6f-7397-4c9d-a83d-c7b5632053b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = \"pyg-point-cloud\" #@param {\"type\": \"string\"}\n",
    "wandb_run_name = \"evaluate-dgcnn\" #@param {\"type\": \"string\"}\n",
    "\n",
    "wandb.init(project=wandb_project, name=wandb_run_name, job_type=\"evaluate\")\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "config.seed = 42\n",
    "config.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)\n",
    "device = torch.device(config.device)\n",
    "\n",
    "config.category = 'Airplane' #@param [\"Bag\", \"Cap\", \"Car\", \"Chair\", \"Earphone\", \"Guitar\", \"Knife\", \"Lamp\", \"Laptop\", \"Motorbike\", \"Mug\", \"Pistol\", \"Rocket\", \"Skateboard\", \"Table\"] {type:\"raw\"}\n",
    "config.random_jitter_translation = 1e-2\n",
    "config.random_rotation_interval_x = 15\n",
    "config.random_rotation_interval_y = 15\n",
    "config.random_rotation_interval_z = 15\n",
    "config.batch_size = 1\n",
    "config.num_workers = 6\n",
    "\n",
    "config.num_nearest_neighbours = 30\n",
    "config.aggregation_operator = \"max\"\n",
    "config.dropout = 0.5\n",
    "config.initial_lr = 1e-3\n",
    "config.lr_scheduler_step_size = 20\n",
    "config.gamma = 0.8\n",
    "\n",
    "config.artifact_address = 'wandb/point-cloud-segmentation/dgcnn-3n97rfrv-checkpoint:v29'\n",
    "config.epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f068eb-5b69-4c73-9e21-4f0d5eab0d9e",
   "metadata": {},
   "source": [
    "# Load ShapeNet Dataset using PyTorch Geometric\n",
    "\n",
    "We now load, preprocess and batch the ModelNet dataset for training, validation/testing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208dc676-c0bf-4a3d-bc5a-5b4251664de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.RandomJitter(config.random_jitter_translation),\n",
    "    T.RandomRotate(config.random_rotation_interval_x, axis=0),\n",
    "    T.RandomRotate(config.random_rotation_interval_y, axis=1),\n",
    "    T.RandomRotate(config.random_rotation_interval_z, axis=2)\n",
    "])\n",
    "pre_transform = T.NormalizeScale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27014b34-cfff-47be-b761-db8c484dad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('ShapeNet', config.category)\n",
    "\n",
    "train_dataset = ShapeNet(\n",
    "    dataset_path, config.category, split='trainval',\n",
    "    transform=transform, pre_transform=pre_transform\n",
    ")\n",
    "test_dataset = ShapeNet(\n",
    "    dataset_path, config.category, split='test',\n",
    "    pre_transform=pre_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0e1df-7522-485b-b697-3dd066d85f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_class_frequency = {}\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    pc_viz = train_dataset[idx].pos.numpy().tolist()\n",
    "    segmentation_label = train_dataset[idx].y.numpy().tolist()\n",
    "    for label in set(segmentation_label):\n",
    "        segmentation_class_frequency[label] = segmentation_label.count(label)\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    pc_viz = train_dataset[idx].pos.numpy().tolist()\n",
    "    segmentation_label = train_dataset[idx].y.numpy().tolist()\n",
    "    for label in set(segmentation_label):\n",
    "        segmentation_class_frequency[label] = segmentation_label.count(label)\n",
    "class_offset = min(list(segmentation_class_frequency.keys()))\n",
    "class_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67c4fa-92b4-495a-a247-c4e8a6c56d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    train_dataset[idx].y -= class_offset\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    test_dataset[idx].y -= class_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147d1c3-9772-4be9-8932-c9238a9270ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size,\n",
    "    shuffle=True, num_workers=config.num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=config.batch_size,\n",
    "    shuffle=False, num_workers=config.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1b72e-cd7b-452f-ac08-dc2155561077",
   "metadata": {},
   "source": [
    "# Load Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a02d75-be84-436a-871c-ccadb863dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=30, aggr='max'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 6, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 64, 64]), k, aggr)\n",
    "        self.conv3 = DynamicEdgeConv(MLP([2 * 64, 64, 64]), k, aggr)\n",
    "\n",
    "        self.mlp = MLP(\n",
    "            [3 * 64, 1024, 256, 128, out_channels],\n",
    "            dropout=0.5, norm=None\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, pos, batch = data.x, data.pos, data.batch\n",
    "        x0 = torch.cat([x, pos], dim=-1)\n",
    "        \n",
    "        x1 = self.conv1(x0, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        x3 = self.conv3(x2, batch)\n",
    "        \n",
    "        out = self.mlp(torch.cat([x1, x2, x3], dim=1))\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1f670-2a87-4083-9ec7-ed07785a5d66",
   "metadata": {},
   "source": [
    "Since we saved the checkpoints as artifacts on our Weights & Biases workspace, we can now fetch and load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb064c-58b4-4887-b31b-d16622405b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_classes = train_dataset.num_classes\n",
    "\n",
    "model = DGCNN(\n",
    "    out_channels=train_dataset.num_classes,\n",
    "    k=config.num_nearest_neighbours,\n",
    "    aggr=config.aggregation_operator\n",
    ").to(device)\n",
    "\n",
    "model_artifact = wandb.use_artifact(config.artifact_address, type='checkpoint')\n",
    "artifact_dir = model_artifact.download()\n",
    "model_checkpoint_path = os.path.join(artifact_dir, \"checkpoint.pt\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_checkpoint_path)[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676bbf9-50be-4a99-9222-427c927bbe57",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e79961-e71c-4a2f-9040-72c6a5b32f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, split, table):\n",
    "    total_accuracy, total_iou = 0, 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            outs = model(data)\n",
    "\n",
    "            predicted_labels = outs.argmax(dim=1)\n",
    "            accuracy = predicted_labels.eq(data.y).sum().item() / data.num_nodes\n",
    "\n",
    "            sizes = (data.ptr[1:] - data.ptr[:-1]).tolist()\n",
    "            ious, categories = [], []\n",
    "            y_map = torch.empty(\n",
    "                loader.dataset.num_classes, device=device\n",
    "            ).long()\n",
    "            for out, y, category in zip(\n",
    "                outs.split(sizes), data.y.split(sizes), data.category.tolist()\n",
    "            ):\n",
    "                category = list(ShapeNet.seg_classes.keys())[category]\n",
    "                part = ShapeNet.seg_classes[category]\n",
    "                part = torch.tensor(part, device=device)\n",
    "                y_map[part] = torch.arange(part.size(0), device=device)\n",
    "                iou = jaccard_index(\n",
    "                    out[:, part].argmax(dim=-1), y_map[y],\n",
    "                    task=\"multiclass\", num_classes=part.size(0)\n",
    "                )\n",
    "                ious.append(iou)\n",
    "            categories.append(data.category)\n",
    "            iou = torch.tensor(ious, device=device)\n",
    "            category = torch.cat(categories, dim=0)\n",
    "            mean_iou = float(scatter(iou, category, reduce='mean').mean())\n",
    "\n",
    "            gt_pc_viz = data.pos.cpu().numpy().tolist()\n",
    "            segmentation_label = data.y.cpu().numpy().tolist()\n",
    "            frequency_dict = {key: 0 for key in segmentation_class_frequency.keys()}\n",
    "            for label in set(segmentation_label):\n",
    "                frequency_dict[label] = segmentation_label.count(label)\n",
    "            for j in range(len(gt_pc_viz)):\n",
    "                gt_pc_viz[j] += [segmentation_label[j] + 1 - class_offset]\n",
    "\n",
    "            predicted_pc_viz = data.pos.cpu().numpy().tolist()\n",
    "            segmentation_label = data.y.cpu().numpy().tolist()\n",
    "            frequency_dict = {key: 0 for key in segmentation_class_frequency.keys()}\n",
    "            for label in set(segmentation_label):\n",
    "                frequency_dict[label] = segmentation_label.count(label)\n",
    "            for j in range(len(predicted_pc_viz)):\n",
    "                predicted_pc_viz[j] += [segmentation_label[j] + 1 - class_offset]\n",
    "\n",
    "            table.add_data(\n",
    "                wandb.Object3D(np.array(gt_pc_viz)),\n",
    "                wandb.Object3D(np.array(predicted_pc_viz)),\n",
    "                accuracy, mean_iou, split, \"DGCNN\"\n",
    "            )\n",
    "            total_accuracy += accuracy\n",
    "            total_iou += mean_iou\n",
    "    \n",
    "    wandb.log({\n",
    "        f\"{split}/Accuracy\": total_accuracy / len(loader),\n",
    "        f\"{split}/IoU\": total_iou / len(loader),\n",
    "    })\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5f0bb-01b1-48a3-980d-c22434f2be8a",
   "metadata": {},
   "source": [
    "We evaluate the results and store them in a Weights & Biases Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427209c-216a-4887-9b3b-a73c474680c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\"Ground-Truth\", \"Prediction\", \"Accuracy\", \"IoU\", \"Split\", \"Model-Name\"])\n",
    "evaluate(train_loader, \"Train-Val\", table)\n",
    "evaluate(test_loader, \"Test\", table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1688f54-ef52-4f42-a6f6-b5c3364da87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Evaluation-Results\": table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd8610-bda8-4e7b-9939-b1e7b7b4e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c44316-de14-4031-b6d2-ba8c9621a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
