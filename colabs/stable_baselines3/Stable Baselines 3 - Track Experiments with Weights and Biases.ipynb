{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "W&B and SB3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Baselines 3 - Track Experiments with Weights and Biases\n",
        "\n",
        "Github repo: https://github.com/araffin/rl-tutorial-jnrr19\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines.readthedocs.io/en/master/\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "Weights & Biases: https://wandb.ai/site\n",
        "\n",
        "Weights & Biases Docs: https://docs.wandb.ai/\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "<!--- @wandbcode{wandb-colab} -->\n",
        "[Weights & Biases (W&B)](https://wandb.ai/site) is a tool for machine learning experiment tracking, dataset versioning, and project collaboration.\n",
        "\n",
        "<div><img /></div>\n",
        "\n",
        "<img src=\"https://i.imgur.com/uEtWSEb.png\" width=\"650\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<div><img /></div>\n",
        "\n",
        "In this notebook, you will learn how to track reinforcement learning experiments using W&B. In particular, W&B helps track your experiment configs, metrics, and videos of the agents playing the game. At the end, you should see a run page like https://wandb.ai/wandb/cartpole_test/runs/37ppqzxc \n",
        "\n",
        "## Install Dependencies and Set up Virtual Displays for Video Recordings\n",
        "\n"
      ],
      "metadata": {
        "id": "fA1yucrYKx0Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!apt install python-opengl xvfb\n",
        "!pip install pyvirtualdisplay stable_baselines3[extra] git+https://github.com/wandb/client.git\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "outputs": [],
      "metadata": {
        "id": "47bVDhSDPywL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Track experiments with W&B\n",
        "\n",
        "Here is a clean end-to-end example to run. It will prompt you to login in to W&B if you haven't. \n"
      ],
      "metadata": {
        "id": "nPlCXGwWFPTI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "\n",
        "\n",
        "config = {\n",
        "    \"policy_type\": \"MlpPolicy\",\n",
        "    \"total_timesteps\": 25000,\n",
        "    \"env_name\": \"CartPole-v1\",\n",
        "}\n",
        "run = wandb.init(\n",
        "    project=\"sb3\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(config[\"env_name\"])\n",
        "    env = Monitor(env)  # record stats such as returns\n",
        "    return env\n",
        "\n",
        "\n",
        "env = DummyVecEnv([make_env])\n",
        "env = VecVideoRecorder(env, \"videos\", record_video_trigger=lambda x: x % 2000 == 0, video_length=200)\n",
        "model = PPO(config[\"policy_type\"], env, verbose=1, tensorboard_log=f\"runs\")\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=WandbCallback(\n",
        "        gradient_save_freq=100,\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "    ),\n",
        ")\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "U99BWKenKcuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After finishing the cell above you should see a dashbaord similar to the gif below:\n",
        "\n",
        "![](https://user-images.githubusercontent.com/5555347/122989248-97b5bd00-d370-11eb-95d6-52d56cfbce19.gif)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ]
}