{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/ayulockin/0689baf60c227371dd51ea1d81e658eb/fine_tune_vision_transformer_using_kerascv.ipynb#scrollTo=JoxvUF2sJe45)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxLX8njJpbQ"
      },
      "source": [
        "# Installations and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUTpCaWBJgtv"
      },
      "outputs": [],
      "source": [
        "!pip install -qq keras-cv\n",
        "!pip install -qq wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoxvUF2sJe45"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from argparse import Namespace\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import keras_cv as kcv\n",
        "from keras_cv.models import ViTTiny16\n",
        "from keras_cv.layers import preprocessing\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger\n",
        "from wandb.keras import WandbEvalCallback\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwOnO8v2J1Vc"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQomoMJTJtYy"
      },
      "outputs": [],
      "source": [
        "configs = Namespace(\n",
        "    learning_rate = 1e-4,\n",
        "    batch_size = 64,\n",
        "    num_epochs = 10,\n",
        "    image_size = 224,\n",
        "    num_classes = 120,\n",
        "    num_steps = 1.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a-h5TY9J6AG"
      },
      "source": [
        "# Dataset and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRxSoJbUJ2-x"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "\n",
        "def parse_data(example):\n",
        "    \"Apply preprocessing to one data sample at a time.\"\n",
        "    image = example[\"image\"]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (configs.image_size, configs.image_size))\n",
        "\n",
        "    label = example[\"label\"]\n",
        "    label = tf.one_hot(label, configs.num_classes)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "base_augmentations = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.RandomRotation(factor=0.02),\n",
        "        tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"base_augmentation\",\n",
        ")\n",
        "\n",
        "mixup = preprocessing.MixUp(alpha=0.8)\n",
        "\n",
        "\n",
        "def apply_base_augmentations(images, labels):\n",
        "    images = base_augmentations(images)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "ds_train, ds_test = tfds.load('stanford_dogs', split=['train', 'test'])\n",
        "\n",
        "trainloader = (\n",
        "    ds_train\n",
        "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(configs.batch_size)\n",
        "    .map(apply_base_augmentations, num_parallel_calls=AUTOTUNE)\n",
        "    .map(lambda images, labels: mixup({\"images\": images, \"labels\": labels}), num_parallel_calls=AUTOTUNE)\n",
        "    .map(lambda x: (x[\"images\"], x[\"labels\"]), num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(1024)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "testloader = (\n",
        "    ds_test\n",
        "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(configs.batch_size)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRzYlUtVJ-yV"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(configs.image_size, configs.image_size, 3))\n",
        "\n",
        "    vit = ViTTiny16(\n",
        "        include_rescaling=False,\n",
        "        include_top=False,\n",
        "        name=\"ViTTiny32\",\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=inputs,\n",
        "        pooling=\"token_pooling\",\n",
        "        activation=tf.keras.activations.gelu,\n",
        "    )\n",
        "    \n",
        "    vit.trainable = True\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(configs.num_classes, activation=\"softmax\")(vit.output)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIUMgqAgKViO"
      },
      "source": [
        "# Compile the Model\n",
        "\n",
        "We will use `CosineDecay` learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV1cEnUbKSxc"
      },
      "outputs": [],
      "source": [
        "total_steps = len(trainloader)*configs.num_epochs\n",
        "decay_steps = total_steps * configs.num_steps\n",
        "\n",
        "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    configs.learning_rate, decay_steps, alpha=0.1\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay_scheduler),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhtvxiCKgA3"
      },
      "source": [
        "# [OPTIONAL] Model Prediction Visualization\n",
        "\n",
        "We will build a custom Keras callback by subclassing `WandbEvalCallback` for model prediction visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkJWab9SKckK"
      },
      "outputs": [],
      "source": [
        "class WandbClfEvalCallback(WandbEvalCallback):\n",
        "    def __init__(\n",
        "        self, validloader, data_table_columns, pred_table_columns, num_samples=100\n",
        "    ):\n",
        "        super().__init__(data_table_columns, pred_table_columns)\n",
        "\n",
        "        self.val_data = validloader.unbatch().take(num_samples)\n",
        "\n",
        "    def add_ground_truth(self, logs=None):\n",
        "        for idx, (image, label) in enumerate(self.val_data):\n",
        "            self.data_table.add_data(\n",
        "                idx,\n",
        "                wandb.Image(image),\n",
        "                np.argmax(label, axis=-1)\n",
        "            )\n",
        "\n",
        "    def add_model_predictions(self, epoch, logs=None):\n",
        "        # Get predictions\n",
        "        preds = self._inference()\n",
        "        table_idxs = self.data_table_ref.get_index()\n",
        "\n",
        "        for idx in table_idxs:\n",
        "            pred = preds[idx]\n",
        "            self.pred_table.add_data(\n",
        "                epoch,\n",
        "                self.data_table_ref.data[idx][0],\n",
        "                self.data_table_ref.data[idx][1],\n",
        "                self.data_table_ref.data[idx][2],\n",
        "                pred\n",
        "            )\n",
        "\n",
        "    def _inference(self):\n",
        "      preds = []\n",
        "      for image, label in self.val_data:\n",
        "          pred = self.model(tf.expand_dims(image, axis=0))\n",
        "          argmax_pred = tf.argmax(pred, axis=-1).numpy()[0]\n",
        "          preds.append(argmax_pred)\n",
        "\n",
        "      return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue3I7al2KzsF"
      },
      "source": [
        "# Train the model with W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg3cXV9zKsrZ",
        "outputId": "41bf4c96-68e1-43ea-cbbe-c573622eab2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 99/188 [==============>...............] - ETA: 33s - loss: 5.5390 - accuracy: 0.0103"
          ]
        }
      ],
      "source": [
        "# Initialize a W&B run\n",
        "run = wandb.init(\n",
        "    project=\"keras_cv_vit\",\n",
        "    save_code=False,\n",
        "    config=vars(configs),\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "model.fit(\n",
        "    trainloader,\n",
        "    epochs=configs.num_epochs,\n",
        "    validation_data=testloader,\n",
        "    callbacks=[\n",
        "        WandbMetricsLogger(log_freq=2),\n",
        "        WandbClfEvalCallback(\n",
        "            validloader = testloader,\n",
        "            data_table_columns = [\"idx\", \"image\", \"label\"],\n",
        "            pred_table_columns = [\"epoch\", \"idx\", \"image\", \"label\", \"pred\"]\n",
        "        )\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QD4etF_LCKL"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw6slRV2K-sm"
      },
      "outputs": [],
      "source": [
        "eval_loss, eval_acc = model.evaluate(testloader)\n",
        "wandb.log({\n",
        "    \"eval_loss\": eval_loss,\n",
        "    \"eval_acc\": eval_acc\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbe8VHQJLDx4"
      },
      "outputs": [],
      "source": [
        "# Close the W&B run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyAvj9QmLJDW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
