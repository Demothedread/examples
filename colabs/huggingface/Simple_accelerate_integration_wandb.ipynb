{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadda531-5f7b-4793-876b-dceedec26cc5",
   "metadata": {},
   "source": [
    "# Using Huggingface Accelerate with Weights and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ccfcf6-5d99-474c-a58e-77783906efb4",
   "metadata": {},
   "source": [
    "[Accelerate](https://github.com/huggingface/accelerate) is this amazing little framework that simplifies your PyTorch training scripts enabling you to train with all the tricks out there!\n",
    "- Quickly convert your code to support multiple hardward (GPUS, TPUs, Metal,...)\n",
    "- One code to support mixed precision, bfloat16 and even 8 bit Adam.\n",
    "\n",
    "Minimal code and no boilerplate. Weights and Biases integration out of the box!\n",
    "\n",
    "```diff\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "  from datasets import load_dataset\n",
    "+ from accelerate import Accelerator\n",
    "\n",
    "+ accelerator = Accelerator(log_with=\"wandb\")\n",
    "+ accelerator.init_trackers(\"my_wandb_project\", config=cfg)\n",
    "- device = 'cpu'\n",
    "+ device = accelerator.device\n",
    "\n",
    "  model = torch.nn.Transformer().to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "  dataset = load_dataset('my_dataset')\n",
    "  data = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
    "\n",
    "+ model, optimizer, data = accelerator.prepare(model, optimizer, data)\n",
    "\n",
    "  model.train()\n",
    "  for epoch in range(10):\n",
    "      for source, targets in data:\n",
    "          source = source.to(device)\n",
    "          targets = targets.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          output = model(source)\n",
    "          loss = F.cross_entropy(output, targets)\n",
    "\n",
    "-         loss.backward()\n",
    "+         accelerator.backward(loss)\n",
    "\n",
    "          optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa793a-f2d3-468c-823e-492d2bebe4b7",
   "metadata": {},
   "source": [
    "## Training and Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83e24e-ad59-4038-8a4b-67f6dcce94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate wandb torcheval timm fastprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc4bba-0181-4a8b-bfc5-6ae87a3c07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as T\n",
    "from torcheval.metrics.toolkit import sync_and_compute\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760c536-636b-4cd9-b244-3bb61254ebd6",
   "metadata": {},
   "source": [
    "Store your configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbcd78-f3f8-4cfc-a89c-5e3767d16e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace(\n",
    "    path=\".\",\n",
    "    bs=256,\n",
    "    epochs=5,\n",
    "    size=28,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "WANDB_PROJECT = \"accelerate_fmnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370911f-7e69-43d3-93ec-50ed271c9ae6",
   "metadata": {},
   "source": [
    "setup transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68787b-43a7-459c-97b8-6b483291a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = T.Compose([\n",
    "    T.RandomCrop(cfg.size, padding=1),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9579d-244c-47ee-9131-51d9ef7aa069",
   "metadata": {},
   "source": [
    "Create a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead4006-6a4e-4009-b9b8-776d1ca1bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_ch, out_ch, ks=3): return nn.Sequential(nn.BatchNorm2d(in_ch),\n",
    "                                                    nn.Conv2d(in_ch, out_ch, ks, stride=2, padding=0), \n",
    "                                                    nn.ReLU())\n",
    "\n",
    "def create_cnn():\n",
    "    return nn.Sequential(nn.Conv2d(1, 16, 5, stride=1, padding=\"same\"),\n",
    "                         conv_block(16, 32),\n",
    "                         conv_block(32, 64),\n",
    "                         conv_block(64, 128),\n",
    "                         conv_block(128, 256, 1),\n",
    "                         nn.Sequential(nn.Flatten(), nn.Linear(256,10), nn.BatchNorm1d(10)),\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f89dd-4e18-4644-9d6a-b7ae7a5447a9",
   "metadata": {},
   "source": [
    "Wrap everything into a training functions (this is necessary to run on multiple GPUS, if it is only one, you can skip the wrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbaf18-655c-4a35-8060-8c25eb7f27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg):\n",
    "\n",
    "    # data\n",
    "    ds = FashionMNIST(cfg.path, transform=tfms, download=True) \n",
    "    dl = DataLoader(ds, batch_size=cfg.bs, num_workers=cfg.num_workers)\n",
    "    \n",
    "    # model\n",
    "    model = create_cnn()\n",
    "    \n",
    "    # training setup\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    \n",
    "    # accelerate\n",
    "    accelerator = Accelerator(log_with=\"wandb\")\n",
    "    \n",
    "    # this will call wandb.init(...)\n",
    "    accelerator.init_trackers(WANDB_PROJECT, config=cfg)\n",
    "    \n",
    "    # prepare\n",
    "    model, optimizer, dl = accelerator.prepare(model, optimizer, dl)\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    for epoch in progress_bar(range(cfg.epochs)):\n",
    "        accurate, num_elems = 0., 0\n",
    "        for source, targets in dl:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(source)\n",
    "            loss = F.cross_entropy(output, targets)\n",
    "            accelerator.backward(loss)\n",
    "            \n",
    "            # under the hood this calls wandb.log(...) on the main process\n",
    "            accelerator.log({\"train_loss\": loss})\n",
    "            \n",
    "            accurate_preds = output.argmax(dim=1) == targets\n",
    "            num_elems += accurate_preds.shape[0]\n",
    "            accurate += accurate_preds.long().sum()\n",
    "            optimizer.step()\n",
    "        accuracy = accurate.item() / num_elems\n",
    "        accelerator.log({\"epoch\":epoch, \"accuracy\":accuracy})\n",
    "        print(f\"epoch: {epoch:3} || loss: {loss:5.3f} || accuracy: {accuracy:5.3f}\")\n",
    "    \n",
    "    # this will call wandb.finish()\n",
    "    accelerator.end_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6227c06-2365-4386-9250-e1c22ac84bec",
   "metadata": {},
   "source": [
    "Let's train on 2 GPUs! This is really nice, as accelerate will take care of only calling `log` on the main process, so only one run get's created, so no need to manually check the rank of the process when using multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f7217-9a0f-4881-9219-38f1a65dbf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tcapelle/wandb/accelerate_integration/wandb/run-20230109_145715-1fqu91eo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/accelerate_upgrade/runs/1fqu91eo\" target=\"_blank\">ethereal-cherry-18</a></strong> to <a href=\"https://wandb.ai/capecape/accelerate_upgrade\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:13&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 || loss: 0.660 || accuracy: 0.736epoch:   0 || loss: 0.783 || accuracy: 0.732\n",
      "\n",
      "epoch:   1 || loss: 0.684 || accuracy: 0.802\n",
      "epoch:   1 || loss: 0.553 || accuracy: 0.804\n",
      "epoch:   2 || loss: 0.614 || accuracy: 0.821\n",
      "epoch:   2 || loss: 0.487 || accuracy: 0.821\n",
      "epoch:   3 || loss: 0.556 || accuracy: 0.833\n",
      "epoch:   3 || loss: 0.427 || accuracy: 0.834\n",
      "epoch:   4 || loss: 0.499 || accuracy: 0.839\n",
      "epoch:   4 || loss: 0.395 || accuracy: 0.841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c783e1d77643afb4fdb6c43c838158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇██</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▇▆▄▄▄▄▄▃▄▃▃▃▃▃▃▂▃▃▃▂▃▃▂▂▂▃▂▂▂▂▂▁▁▂▁▁▂▂▂</td></tr><tr><td>train_loss_2</td><td>█▇▆▄▄▄▄▄▃▄▃▃▃▃▃▃▂▃▃▃▂▃▃▂▂▂▃▂▂▂▂▂▁▁▂▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8413</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.39482</td></tr><tr><td>train_loss_2</td><td>0.39482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-cherry-18</strong>: <a href=\"https://wandb.ai/capecape/accelerate_upgrade/runs/1fqu91eo\" target=\"_blank\">https://wandb.ai/capecape/accelerate_upgrade/runs/1fqu91eo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230109_145715-1fqu91eo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_GPUSs = 2\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(train, (cfg,), num_processes=num_GPUSs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
